{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f030af",
   "metadata": {},
   "source": [
    "1.a)Classification Decision Trees address problems involving the prediction of categorical outcomes. They excel in scenarios where the goal is to classify data into distinct categories or classes.\n",
    "Examples of Real-World Applications:\n",
    "Medical Diagnosis: Predicting whether a patient is likely to have a certain disease based on symptoms and medical history .\n",
    "Spam Filtering: Classifying emails as spam or not spam based on content and sender information .\n",
    "Customer Churn Prediction: Identifying customers who are likely to stop using a service based on their usage patterns and demographics.\n",
    "Credit Risk Assessment: Determining the creditworthiness of loan applicants based on financial history and other factors.\n",
    "Image Recognition: Classifying images into different categories (e.g., cats, dogs, cars) based on visual features. Note that this information is not derived from the sources you provided.\n",
    "\n",
    "b)How a Classification Decision Tree Makes Predictions: A Classification Decision Tree makes predictions by following a series of decision rules organized in a tree-like structure.The tree starts with a root node representing the entire dataset.At each node, a decision rule based on a specific predictor variable splits the data into subsets.This process continues down the tree, creating branches and leaf nodes.Each leaf node represents a final prediction (a specific category).To make a prediction for a new data point, you traverse the tree from the root node down to a leaf node, following the decision rules at each node based on the values of the predictor variables for that data point. The category assigned to the final leaf node is the prediction.\n",
    "\n",
    "How Multiple Linear Regression Makes Predictions: Multiple Linear Regression makes predictions using a linear equation that relates a continuous outcome variable to multiple predictor variables.\n",
    "The equation takes the form:Y = β0 + β1X1 + β2X2 + ... + βnXn,where Y is the predicted outcome, the Xi are the predictor variables, β0 is the intercept, and the βi are the coefficients.The coefficients represent the change in the outcome variable for a one-unit change in the corresponding predictor variable, holding all other variables constant.To make a prediction, you plug in the values of the predictor variables for a new data point into the equation.\n",
    "\n",
    "Key Differences:\n",
    "Outcome Type: Classification Decision Trees predict categorical outcomes, while Multiple Linear Regression predicts continuous outcomes.\n",
    "Prediction Mechanism: Decision Trees use a sequential decision-making process based on rules, while Multiple Linear Regression uses a linear equation to calculate predictions.\n",
    "Interpretability: The importance of different predictor variables in a Decision Tree can be assessed using feature importances, which indicate the relative contribution of each variable to the overall model performance. In Multiple Linear Regression, coefficients provide insights into the magnitude and direction of the relationship between each predictor variable and the outcome, but do not directly translate to overall importance in the way that feature importances do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa32483",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..SUMARRIES \n",
    "SUMMARIES:\n",
    "Classification Decision Trees deal with predicting categorical outcomes, effectively sorting data into distinct classes. Some practical uses include medical diagnoses, spam detection, customer churn prediction, credit risk evaluation, and image recognition.\n",
    "Note that image recognition was not mentioned in the provided sources.\n",
    "To make predictions, a Classification Decision Tree employs a hierarchical, rule-based system:\n",
    "1.Starting at the root node, which encapsulates the whole dataset.\n",
    "2.Each node applies a decision rule based on a predictor variable to divide data into subsets.\n",
    "3.This branching process leads to leaf nodes.\n",
    "4.Every leaf node represents a final prediction, indicating a specific category.Multiple Linear Regression, on the other hand, uses a linear equation to predict a continuous outcome based on various predictor variables. The equation:Y = β0 + β1X1 + β2X2 + ... + βnXn.where Y represents the predicted outcome.Xi represents the predictor variables, β0 is the intercept, and βi represents the coefficients.\n",
    "\n",
    "Key Differences\n",
    "Outcome Type: Classification Decision Trees are designed for categorical outcomes, while Multiple Linear Regression is used for continuous outcomes.\n",
    "Prediction Method: Decision Trees utilize a sequential, rule-based decision-making process, whereas Multiple Linear Regression employs a linear equation.\n",
    "Interpretability: Feature importances in Decision Trees illustrate the relative significance of predictor variables in overall model performance1 2 . In contrast, coefficients in Multiple Linear Regression indicate the magnitude and direction of the relationship between each predictor variable and the outcome3 . Coefficients do not directly represent overall importance in the same manner that feature importances do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c6860",
   "metadata": {},
   "source": [
    "2.Real-World Applications of Classification Metrics\n",
    "\n",
    "1）Accuracy：\n",
    "Application: A company is sending out marketing emails to a large customer base. They want to measure the overall effectiveness of their email campaign, considering both customers who responded positively (clicked on links, made purchases) and those who didn't.\n",
    "Rationale: Accuracy is a good general measure of a model's performance when the classes (positive and negative) are relatively balanced and the costs of false positives and false negatives are roughly equal. In this email campaign scenario, the company is interested in the overall proportion of correctly classified customers (those who engaged and those who didn't), making accuracy a suitable metric.\n",
    "2）Sensitivity (Recall)\n",
    "Application: A medical test is being developed to screen for a rare but serious disease. It's crucial to identify as many actual cases (true positives) as possible, even if it means having some false positives.\n",
    "Rationale: Sensitivity focuses on correctly identifying all actual positives. In a medical screening context, missing a true case (false negative) can have severe consequences. High sensitivity is crucial to ensure that as many individuals with the disease as possible are correctly identified, even if it leads to some healthy individuals being incorrectly flagged (false positives).\n",
    "3）Specificity\n",
    "Application: A security system is being designed to grant access to a secure facility. It's essential to minimize false positives (granting access to unauthorized individuals) while still maintaining a reasonable level of true positives (granting access to authorized individuals).\n",
    "Rationale: Specificity measures the ability to correctly identify actual negatives. In a security system, a high specificity is crucial to minimize the risk of unauthorized access. By focusing on minimizing false positives, the system ensures that only authorized personnel are granted entry.\n",
    "4）Precision\n",
    "Application: A recommendation system is suggesting products to customers on an e-commerce website. The focus is on ensuring that the recommended products are highly relevant to the customer's interests, even if it means missing out on some potential recommendations.\n",
    "Rationale: Precision is concerned with the accuracy of positive predictions. In a recommendation system, high precision ensures that the recommended items are truly relevant to the customer. This is particularly important to avoid overwhelming the customer with irrelevant suggestions and maintain trust in the recommendations.\n",
    "Important Note: The choice of the most appropriate metric depends on the specific context of the application and the relative costs associated with different types of errors (false positives and false negatives)1 2 . For example, in medical diagnosis, the cost of a false negative (missing a disease) is often much higher than the cost of a false positive (unnecessary further testing)1 . Therefore, sensitivity would be prioritized over specificity in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a601d26",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARIES:Accuracy is a useful metric for evaluating the overall effectiveness of a model when the classes are balanced and the costs of false positives and false negatives are roughly equal. Accuracy gives the proportion of true results, both true positives and true negatives.For instance, a company that wants to measure the overall effectiveness of an email marketing campaign might use accuracy because it considers both customers who responded positively and those who did not.\n",
    "Sensitivity is a metric that should be prioritized when the cost of a false negative is much higher than the cost of a false positive. Sensitivity measures the ability of a model to identify all actual positives.\n",
    "For instance, a medical test that screens for a serious disease would prioritize sensitivity to ensure that most individuals with the disease are correctly identified, even if it leads to some healthy individuals being incorrectly flagged.\n",
    "Specificity measures the proportion of actual negatives that are correctly identified. A model with high specificity is desirable when minimizing false positives is essential.\n",
    "For example, a security system would prioritize specificity to minimize granting access to unauthorized individuals.\n",
    "Precision is a metric that is focused on the accuracy of positive predictions. Precision is useful when it is important to ensure that positive predictions are truly relevant.\n",
    "For example, a recommendation system on an e-commerce website might use precision to ensure that the recommended products are relevant to the customer's interests.\n",
    "The most appropriate metric depends on the specific context of the application and the costs associated with different types of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697caff4",
   "metadata": {},
   "source": [
    "3.Import Necessary Libraries1 : First, import the required libraries for data manipulation, analysis, and visualization:\n",
    "Load the Dataset1 : Load the Amazon books dataset from the provided URL:\n",
    "Remove Unnecessary Columns1 : Drop the columns 'Weight_oz', 'Width', and 'Height' as they are not required for the analysis:\n",
    "Handle Missing Values1 : Drop any rows that contain NaN entries to ensure data completeness for the analysis:\n",
    "Adjust Data Types1 : Convert the data types of 'Pub year' and 'NumPages' to integers and 'Hard_or_Paper' to a categorical type:\n",
    "\n",
    "Exploratory Data Analysis (EDA)2 : Now that the dataset is preprocessed, perform some initial EDA:\n",
    "Descriptive Statistics: Use the describe() method to get a summary of the numerical variables (List Price, NumPages, Pub year). Pay attention to measures like mean, standard deviation, minimum, maximum, and quartiles to understand the distribution of these variables.\n",
    "Data Visualization: Create histograms or boxplots to visualize the distributions of numerical variables. You can also use scatterplots to explore relationships between variables like 'List Price' and 'NumPages'.1 3\n",
    "Categorical Variable Exploration: Analyze the distribution of the 'Hard_or_Paper' variable. Calculate the frequency of each category to understand the proportion of hardcover and paperback books in the dataset.1 3\n",
    "\n",
    "Data Summarization: Summarize your findings from the EDA.\n",
    "Describe the general characteristics of the dataset, such as the number of observations and variables after pre-processing.\n",
    "Highlight any interesting patterns or insights observed during the exploration, such as relationships between variables or the distribution of specific variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3a54f",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:\n",
    "The first step is to import necessary libraries for data manipulation, analysis, and visualization using Python.\n",
    "Load the Amazon books dataset from the given URL using the read_csv function from the Pandas library.\n",
    "The next step is to remove unnecessary columns ('Weight_oz', 'Width', and 'Height') from the dataset. This can be done using the drop method in Pandas.\n",
    "To handle missing values in the dataset, drop any rows that contain NaN entries. This ensures data completeness for analysis. This can be achieved using the dropna method in Pandas.\n",
    "Convert the data types of 'Pub year' and 'NumPages' columns to integers and the 'Hard_or_Paper' column to a categorical type using the astype method in Pandas.\n",
    "Once the dataset is pre-processed, perform an initial Exploratory Data Analysis (EDA).\n",
    "Calculate descriptive statistics for numerical variables, such as 'List Price', 'NumPages', and 'Pub year' using the describe method in Pandas. This helps to understand the central tendency, dispersion, and range of these variables.\n",
    "Visualize the distribution of numerical variables using histograms or boxplots. Explore the relationship between variables such as 'List Price' and 'NumPages' using scatterplots.\n",
    "For categorical variables, analyze the distribution of 'Hard_or_Paper'. Calculate the frequency of each category to understand the proportion of hardcover and paperback books in the dataset.\n",
    "Finally, summarize your findings from the EDA. Describe the general characteristics of the dataset, such as the number of observations and variables after pre-processing. Note any interesting patterns or relationships between variables and discuss the distribution of specific variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbfbf6f",
   "metadata": {},
   "source": [
    "4.Split the Data: To create the training and testing sets, use the train_test_split function from scikit-learn. Set the random_state parameter to ensure reproducibility. The sources suggest an 80/20 split for training and testing data, respectively1 .\n",
    "Understand the Data Preparation: Before fitting the DecisionTreeClassifier model, let's break down the code provided:\n",
    "pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']: This line creates dummy variables for the \"Hard_or_Paper\" column. The resulting y will be a Pandas Series containing 1s for hardcover books and 0s for paperbacks. The 'H' is selecting the column representing hardcover books1 .\n",
    "X = ab_reduced_noNaN[['List Price']]: This line selects the \"List Price\" column as the predictor variable (X)1 .\n",
    "Train the Model: The sources recommend using the ab_reduced_noNaN_train data to fit the classification tree. This is because the model should learn from the training data and then be evaluated on unseen data (ab_reduced_noNaN_test) to assess its ability to generalize. Using the entire dataset or the test data for initial fitting would lead to overfitting and an inaccurate estimate of the model's performance2 .\n",
    "This code snippet imports the DecisionTreeClassifier, initializes it with a max depth of 2, and then fits it using the \"List Price\" variable from the training data (ab_reduced_noNaN_train[['List Price']]) to predict the 'y_train' (whether a book is hardcover).\n",
    "Visualize and Explain Predictions: Using tree.plot_tree(clf) will visualize the decision tree. However, for better readability, consider using graphviz as suggested in the sources3 . To explain how predictions are made, you'll need to interpret the decision rules at each node of the tree, which will be based on \"List Price\" in this case. The decision tree will split the data based on \"List Price\" to predict whether a book is a hardcover. The max_depth of limits the tree to two levels of splits. You may refer to  for examples of visualizing your tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Simulated dataset (replace with your actual dataset)\n",
    "data = {\n",
    "    \"feature1\": range(1, 101),\n",
    "    \"feature2\": range(101, 201),\n",
    "    \"label\": [0, 1] * 50\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Creating an 80/20 split with a random seed for reproducibility\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reporting the sizes of the datasets\n",
    "print(f\"Number of observations in training set: {train.shape[0]}\")\n",
    "print(f\"Number of observations in testing set: {test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(\n",
    "    clf,\n",
    "    feature_names=['List Price'],  # Feature name\n",
    "    class_names=['Paperback', 'Hardcover'],  # Class names\n",
    "    filled=True,  # Fill colors to represent classes\n",
    "    rounded=True,  # Rounded corners for clarity\n",
    "    precision=2  # Precision for floating-point numbers\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11214446",
   "metadata": {},
   "source": [
    "1） Split the data into training and testing sets\n",
    "You need to perform an 80/20 split of ab_reduced_noNaN into ab_reduced_noNaN_train and ab_reduced_noNaN_test using either df.sample or train_test_split from sklearn. To ensure reproducibility, set a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80/20 split\n",
    "ab_reduced_noNaN_train, ab_reduced_noNaN_test = train_test_split(\n",
    "    ab_reduced_noNaN, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Report the sizes\n",
    "print(f\"Training set size: {len(ab_reduced_noNaN_train)}\")\n",
    "print(f\"Testing set size: {len(ab_reduced_noNaN_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42d9e7",
   "metadata": {},
   "source": [
    "2） Understand what .fit(...) does for DecisionTreeClassifier\n",
    "The .fit(X, y) method in scikit-learn trains the DecisionTreeClassifier. It builds a decision tree by splitting the data at different feature values to minimize impurity (e.g., Gini index or entropy).\n",
    "3）Prepare the variables for the model\n",
    "Use the List Price variable (X) to predict whether a book is hard cover (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d785300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare X and y\n",
    "y = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']\n",
    "X = ab_reduced_noNaN_train[['List Price']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c151a08",
   "metadata": {},
   "source": [
    "4）Train the classification tree\n",
    "Fit the model using DecisionTreeClassifier with a maximum depth of 2. This depth limits the number of splits in the tree, ensuring simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize and train the classifier\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Visualize the tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "tree.plot_tree(clf, feature_names=['List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8193abd",
   "metadata": {},
   "source": [
    "5）Predictions and decision tree explanation\n",
    "The decision tree splits the List Price variable into ranges to classify books as either \"hard cover\" or \"paper back\". Each leaf node provides a class label (hard or paper) based on the majority class in the split.\n",
    "\n",
    "For example:\n",
    "\n",
    "If List Price <= split_1_value, predict \"Paper.\"\n",
    "If List Price > split_1_value and <= split_2_value, predict \"Hard.\"\n",
    "Beyond split_2_value, predict the next class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565f35b2",
   "metadata": {},
   "source": [
    "6）Answer: Should you use the training or testing set for .fit(...)?\n",
    "Always use the training data (ab_reduced_noNaN_train) to fit the model. The testing data (ab_reduced_noNaN_test) should only be used to evaluate the model’s performance to ensure no data leakage or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5bca7d",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:The previous response explains how to split the data, prepare it for a DecisionTreeClassifier model, train the model, and visualize and explain the predictions made.\n",
    "Splitting the Data: Use the train_test_split function from scikit-learn to create the training and testing sets1 . This is crucial for evaluating the model's ability to generalize to new, unseen data2 . A random seed, set using the random_state parameter, ensures that the split is reproducible3 . Split the data with 80% for training (ab_reduced_noNaN_train) and 20% for testing (ab_reduced_noNaN_test)3 . After performing the split, print the number of observations in each set3 .\n",
    "Data Preparation: This step prepares the data for the DecisionTreeClassifier model .\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']: This line creates dummy variables for the \"Hard_or_Paper\" column, representing hardcover books with 1 and paperbacks with 04 . The 'H' selects the column representing hardcover books.\n",
    "X = ab_reduced_noNaN[['List Price']]: This line selects the \"List Price\" column as the predictor variable (X)4 .\n",
    "Model Training: The DecisionTreeClassifier model is trained using the training data (ab_reduced_noNaN_train) to avoid overfitting2 5 . Overfitting occurs when the model memorizes the training data and fails to perform well on unseen data .\n",
    "This code imports the DecisionTreeClassifier from scikit-learn, initializes a classifier (clf) with a max_depth of 2, and then trains the model using the \"List Price\" from the training data and the corresponding outcome variable (y_train) .\n",
    "Visualization and Prediction Explanation: Visualize the trained decision tree using tree.plot_tree(clf) or graphviz for better readability8 9 . The visualization will show how the tree splits the data based on \"List Price\" to predict whether a book is a hardcover9 . The max_depth of 2 restricts the tree to two levels of splits9 . The specific predictions will depend on the fitted model and the training data used. You did not provide the code for generating y_train, which should be created by selecting the subset of the outcome variable (y) that corresponds to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323dc98",
   "metadata": {},
   "source": [
    "5.Define Predictor Variables: The predictor variables (X) are defined as 'NumPages', 'Thick', and 'List Price' from the 'ab_reduced_noNaN' dataframe:\n",
    "Prepare the Outcome Variable: The outcome variable (y) should be prepared as in the previous steps to represent hardcover books as 1 and paperbacks as 0:\n",
    "Split the Data: Utilize the existing train/test split (ab_reduced_noNaN_train and ab_reduced_noNaN_test) created previously. This ensures consistency and allows the evaluation of the new model (clf2) on the same unseen data.\n",
    "Train the Decision Tree: Initialize a new DecisionTreeClassifier (clf2) with max_depth set to 4 and train it using the predictor variables (X_train) from the training data and corresponding outcome variable (y_train):\n",
    "Setting max_depth to 4 allows for a more complex tree than the previous clf model, which had a max_depth of 2. This increased complexity might improve the model's ability to capture the relationships in the data but also increases the risk of overfitting.\n",
    "Visualize the Decision Tree: Visualize the trained clf2 model. Using tree.plot_tree(clf2) will create a basic visualization, but the sources suggest using graphviz for improved readability. Remember that you will need to install graphviz (pip install graphviz) and import it into your Python environment before using it.\n",
    "Explain How Predictions are Made: To explain the predictions made by clf2, interpret the decision rules at each node of the visualized tree. Each node represents a decision point based on one of the predictor variables ('NumPages', 'Thick', or 'List Price'). The branches stemming from each node represent the possible outcomes of that decision. By following the branches down the tree based on the values of the predictor variables for a given book, you arrive at a leaf node that predicts whether the book is a hardcover or paperback. The tree will split the data based on these features, with the max_depth of 4 limiting the tree to four levels of splits.\n",
    "Keep in mind that the specific predictions based on 'NumPages', 'Thick', and 'List Price' will depend on the fitted model (clf2) and the training data. The visualization of the tree will provide the specific decision rules and thresholds used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b64f975",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:Define Predictor Variables: Choose the variables from the dataset that will be used to predict the outcome. In this case, the predictor variables (X) are specified as 'NumPages', 'Thick', and 'List Price' from the 'ab_reduced_noNaN' dataframe1 . This step involves selecting the relevant columns from the dataframe.\n",
    "Prepare the Outcome Variable: Ensure the outcome variable (y) is appropriately formatted, typically as a binary variable representing the two classes. In this case, it should represent hardcover books as 1 and paperbacks as 01 . This step might involve creating dummy variables from a categorical variable.\n",
    "Split the Data: Divide the data into training and testing sets to evaluate the model's ability to generalize to unseen data2 3 . This step is crucial in machine learning to avoid overfitting, where the model performs well on the training data but poorly on new data. The sources recommend using the previously created train/test split (ab_reduced_noNaN_train and ab_reduced_noNaN_test) for consistency1 3 .\n",
    "Train the Decision Tree: Initialize a DecisionTreeClassifier with the desired parameters, such as max_depth, and train it using the training data (X_train and y_train)1 4 . The max_depth parameter limits the complexity of the tree and helps prevent overfitting1 5 . A deeper tree with a higher max_depth might capture more complex relationships in the data but also increases the risk of overfitting1 6 .\n",
    "Visualize the Decision Tree: Create a visual representation of the trained decision tree to understand its structure and decision-making process1 7 . You can use tree.plot_tree for a basic visualization or graphviz for a more readable output1 7 .\n",
    "Explain How Predictions are Made: Interpret the decision rules at each node of the visualized tree1 8 . Each node represents a decision based on one of the predictor variables, and the branches represent the possible outcomes of that decision . Following the branches down the tree based on the values of the predictor variables leads to a leaf node, which provides the prediction1 8 . The specific predictions will depend on the fitted model and the training data .\n",
    "The sources highlight the importance of using separate training and testing sets to evaluate the model's performance on unseen data2 . They also emphasize that a decision tree can become complex as the max_depth increases . Visualizing the tree helps to understand the decision-making process, which can be intricate due to the interactions between predictor variables9 . Additionally, sources mention that while a deeper tree may capture more complex relationships in the training data, it may not generalize well to new data, leading to overfitting6 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febee2e",
   "metadata": {},
   "source": [
    "6.Understanding Confusion Matrices:1 2 3  Confusion matrices are used to evaluate the performance of classification models. They provide a visual representation of the model's predictions compared to the actual outcomes. The matrix is structured as follows:\n",
    "True Positive (TP): The model correctly predicted a positive outcome.\n",
    "True Negative (TN): The model correctly predicted a negative outcome.\n",
    "False Positive (FP): The model incorrectly predicted a positive outcome when the actual outcome was negative (also known as a Type I error).4 5\n",
    "False Negative (FN): The model incorrectly predicted a negative outcome when the actual outcome was positive (also known as a Type II error).4 5\n",
    "Defining Positive and Negative:1 3  In the context of the provided sources and the conversation history, \"positive\" refers to a hardcover book, and \"negative\" refers to a paperback book.\n",
    "Creating Confusion Matrices in scikit-learn: To create confusion matrices in scikit-learn, you'll use the confusion_matrix function. It takes two arguments:\n",
    "y_true: The true labels of the data.\n",
    "y_pred: The predicted labels from the model.\n",
    "Calculating Performance Metrics:3 4  You can calculate the sensitivity, specificity, and accuracy from the values in the confusion matrix:\n",
    "1.\n",
    "Accuracy: The proportion of correct predictions (both true positives and true negatives) out of all predictions. $$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "2.\n",
    "Sensitivity (Recall): The proportion of actual positives that are correctly identified as positives. $$\\text{Sensitivity} = \\frac{TP}{TP + FN}$$\n",
    "3.\n",
    "Specificity: The proportion of actual negatives that are correctly identified as negatives. $$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n",
    "Applying These Concepts to Your Query:\n",
    "1.\n",
    "Make Predictions: Use the .predict() method on your trained models (clf and clf2) with the predictor variables from your test data (ab_reduced_noNaN_test) to get the predicted labels (y_pred for both models).\n",
    "2.\n",
    "Create Confusion Matrices: Use the confusion_matrix function to create confusion matrices for both clf and clf2. Ensure you pass the true labels from your test data (y_test, which should represent whether the books in the test set are hardcover or paperback) and the corresponding predicted labels (y_pred for each model) to the function.\n",
    "3.\n",
    "Calculate Metrics: Based on the values in the confusion matrices, calculate the accuracy, sensitivity, and specificity for both models using the formulas provided above. Use np.round() to round the values to three significant digits as instructed in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e870119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Generate predictions for clf and clf2 using the test data\n",
    "y_test = ab_reduced_noNaN_test['life_exp_good']  # Replace with the actual test labels\n",
    "y_pred_clf = clf.predict(ab_reduced_noNaN_test[[\"List Price\"]])\n",
    "y_pred_clf2 = clf2.predict(ab_reduced_noNaN_test[[\"NumPages\", \"Thick\", \"List Price\"]])\n",
    "\n",
    "# Calculate confusion matrices\n",
    "cm_clf = confusion_matrix(y_test, y_pred_clf, labels=[0, 1])\n",
    "cm_clf2 = confusion_matrix(y_test, y_pred_clf2, labels=[0, 1])\n",
    "\n",
    "# Visualize confusion matrices\n",
    "ConfusionMatrixDisplay(cm_clf, display_labels=['Paper', 'Hard']).plot()\n",
    "ConfusionMatrixDisplay(cm_clf2, display_labels=['Paper', 'Hard']).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to calculate evaluation metrics\n",
    "def calculate_metrics(cm):\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    sensitivity = TP / (TP + FN)  # True Positive Rate\n",
    "    specificity = TN / (TN + FP)  # True Negative Rate\n",
    "    accuracy = (TP + TN) / cm.sum()  # Overall accuracy\n",
    "    return round(sensitivity, 3), round(specificity, 3), round(accuracy, 3)\n",
    "\n",
    "# Metrics for clf\n",
    "sensitivity_clf, specificity_clf, accuracy_clf = calculate_metrics(cm_clf)\n",
    "print(f\"clf -> Sensitivity: {sensitivity_clf}, Specificity: {specificity_clf}, Accuracy: {accuracy_clf}\")\n",
    "\n",
    "# Metrics for clf2\n",
    "sensitivity_clf2, specificity_clf2, accuracy_clf2 = calculate_metrics(cm_clf2)\n",
    "print(f\"clf2 -> Sensitivity: {sensitivity_clf2}, Specificity: {specificity_clf2}, Accuracy: {accuracy_clf2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 加载数据\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# 创建数据集，删除空值\n",
    "ab_reduced_noNaN = ab.dropna()\n",
    "\n",
    "# 80/20 数据集拆分\n",
    "ab_reduced_noNaN_train, ab_reduced_noNaN_test = train_test_split(\n",
    "    ab_reduced_noNaN, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 准备训练集和测试集\n",
    "y_train = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']\n",
    "X_train = ab_reduced_noNaN_train[['List Price']]\n",
    "y_test = pd.get_dummies(ab_reduced_noNaN_test[\"Hard_or_Paper\"])['H']\n",
    "X_test = ab_reduced_noNaN_test[['List Price']]\n",
    "\n",
    "# 训练模型 clf 和 clf2\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "clf2 = tree.DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# 模型预测\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_pred_clf2 = clf2.predict(X_test)\n",
    "\n",
    "# 混淆矩阵计算\n",
    "cm_clf = confusion_matrix(y_test, y_pred_clf)\n",
    "cm_clf2 = confusion_matrix(y_test, y_pred_clf2)\n",
    "\n",
    "# 混淆矩阵可视化\n",
    "disp_clf = ConfusionMatrixDisplay(confusion_matrix=cm_clf, display_labels=['Paper', 'Hard'])\n",
    "disp_clf.plot(cmap=\"Blues\", values_format=\".3f\")\n",
    "plt.title(\"Confusion Matrix for clf\")\n",
    "plt.show()\n",
    "\n",
    "disp_clf2 = ConfusionMatrixDisplay(confusion_matrix=cm_clf2, display_labels=['Paper', 'Hard'])\n",
    "disp_clf2.plot(cmap=\"Blues\", values_format=\".3f\")\n",
    "plt.title(\"Confusion Matrix for clf2\")\n",
    "plt.show()\n",
    "\n",
    "# 计算性能指标（敏感度、特异性、准确率）\n",
    "TP_clf, TN_clf, FP_clf, FN_clf = cm_clf[1, 1], cm_clf[0, 0], cm_clf[0, 1], cm_clf[1, 0]\n",
    "sensitivity_clf = np.round(TP_clf / (TP_clf + FN_clf), 3)\n",
    "specificity_clf = np.round(TN_clf / (TN_clf + FP_clf), 3)\n",
    "accuracy_clf = np.round((TP_clf + TN_clf) / np.sum(cm_clf), 3)\n",
    "\n",
    "TP_clf2, TN_clf2, FP_clf2, FN_clf2 = cm_clf2[1, 1], cm_clf2[0, 0], cm_clf2[0, 1], cm_clf2[1, 0]\n",
    "sensitivity_clf2 = np.round(TP_clf2 / (TP_clf2 + FN_clf2), 3)\n",
    "specificity_clf2 = np.round(TN_clf2 / (TN_clf2 + FP_clf2), 3)\n",
    "accuracy_clf2 = np.round((TP_clf2 + TN_clf2) / np.sum(cm_clf2), 3)\n",
    "\n",
    "# 打印结果\n",
    "print(\"模型 clf:\")\n",
    "print(f\"敏感度 (Sensitivity): {sensitivity_clf}\")\n",
    "print(f\"特异性 (Specificity): {specificity_clf}\")\n",
    "print(f\"准确率 (Accuracy): {accuracy_clf}\")\n",
    "\n",
    "print(\"\\n模型 clf2:\")\n",
    "print(f\"敏感度 (Sensitivity): {sensitivity_clf2}\")\n",
    "print(f\"特异性 (Specificity): {specificity_clf2}\")\n",
    "print(f\"准确率 (Accuracy): {accuracy_clf2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae27f69",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:Confusion Matrix: The answer begins by explaining what a confusion matrix is and its structure. It defines the four categories within the matrix: True Positive (TP), True Negative (TN), False Positive (FP), and False Negative (FN). It also clarifies that in this context, \"positive\" refers to a hardcover book, and \"negative\" refers to a paperback book, based on the previous conversation history.\n",
    "Scikit-learn Implementation: It explains how to create confusion matrices in scikit-learn using the confusion_matrix function. The function requires two inputs: y_true (the actual labels from the test data) and y_pred (the predicted labels from the model).3\n",
    "Performance Metrics: It provides the formulas for calculating accuracy, sensitivity, and specificity from the values in the confusion matrix. It emphasizes using np.round() to round the results to three significant digits as instructed in the sources.\n",
    "Steps to Follow: It outlines the steps to answer the query:\n",
    "1.\n",
    "Generate predictions using the .predict() method of the trained models (clf and clf2) on the test data.\n",
    "2.\n",
    "Create the confusion matrices using the confusion_matrix function with the true labels (y_test) and the predicted labels.3\n",
    "3.\n",
    "Calculate the accuracy, sensitivity, and specificity for both models using the formulas provided.\n",
    "Additional Points: The response also emphasizes the importance of evaluating model performance on the unseen test data to assess its real-world applicability.5 11  It suggests visualizing the confusion matrices, although the sources do not provide specific guidance on this, recommending looking for examples online. It also highlights that the models clf and clf2 might have different complexities due to different max_depth settings, which will influence their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484bee23",
   "metadata": {},
   "source": [
    "7.The differences between the two confusion matrices stem from the predictor variables used in the models clf and clf21 . The first confusion matrix is for a decision tree (clf) using only 'List Price' to predict whether a book is hardcover or paperback, while the second confusion matrix is for a decision tree (clf2) using 'NumPages', 'Thick', and 'List Price' as predictor variables1 . The second confusion matrix (clf2) likely exhibits better performance metrics like accuracy, sensitivity, and specificity1 2  because using additional predictor variables can improve a model's ability to identify patterns and make more accurate predictions3 4 . It's also important to remember that the models are evaluated on the ab_reduced_noNaN_train data, meaning they are \"in-sample\" metrics and may not generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bb308",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:The previous response explained that the differences observed in the two confusion matrices result from the different sets of predictor variables used in the models clf and clf21 . The first confusion matrix corresponds to a decision tree model (clf) that uses only 'List Price' to predict if a book is hardcover or paperback. The second confusion matrix corresponds to a decision tree (clf2) that uses 'NumPages', 'Thick', and 'List Price' to predict whether a book is hardcover or paperback.\n",
    "The previous response suggested that the second confusion matrix (clf2) is likely to show better performance because using more predictor variables can enhance a model's ability to find patterns and make more accurate predictions1 . This idea is supported in the sources, which explain that Machine Learning strives to improve predictive performance by increasing model complexity, which includes incorporating more features and interactions between features. Each new level in a Decision Tree introduces another interaction of the existing decision rules with the newly added rule. Therefore, a decision tree using 'NumPages', 'Thick', and 'List Price' would be more complex than a decision tree using only 'List Price.'\n",
    "However, it's crucial to remember that the provided confusion matrices are based on evaluating the models on the ab_reduced_noNaN_train data1 . This means the reported metrics reflect the models' performance on the data they were trained on (\"in-sample\" performance) and might not accurately represent how well they will generalize to new, unseen data (\"out-of-sample\" performance). The sources highlight the distinction between \"in-sample\" and \"out-of-sample\" performance, emphasizing the importance of evaluating a model's performance on data it has not been trained on to assess its true predictive capability.\n",
    "Therefore, while the second confusion matrix (clf2) might appear to have better performance based on the ab_reduced_noNaN_train data, it's essential to evaluate both models on a separate test dataset (ab_reduced_noNaN_test) to determine which model truly generalizes better and makes more accurate predictions on new data. This evaluation using the test dataset aligns with the Machine Learning principle of using regularization tuning parameters to control model complexity and achieve optimal predictive performance on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6438cd29",
   "metadata": {},
   "source": [
    "8.The sources explain that Decision Trees can be complex models because their predictions result from traversing a tree structure based on decision rules at each node1 2 . The feature importance metric was created to assess the relative importance of different features (i.e., predictor variables) in Decision Tree predictions3 .\n",
    "To understand and visualize feature importance for the clf2 model, you can use the .feature_importances_ attribute of the fitted Decision Tree object. This attribute provides an array of values representing the importance of each feature. Additionally, you can use the .feature_names_in_ attribute to get the names of the features corresponding to the importance values4 .\n",
    "By combining these two attributes, you can create a visualization, such as a bar plot, to show the relative importance of each predictor variable in the clf2 model. The source material does not include instructions for creating visualizations, so you may want to refer to the sklearn documentation or other resources for guidance.\n",
    "The sources note that the feature importance metric can be helpful in understanding how classification decision trees use features to make predictions, especially since Decision Trees lack the interpretable linear forms of linear models like Multiple Linear Regression\n",
    "\n",
    "Multiple linear regression models have a simple and interpretable structure. The coefficients of the linear equation directly show how each covariate (i.e., predictor variable) contributes to the final predicted value.\n",
    "Decision trees, on the other hand, are far more complex because their predictions are determined by a series of decision rules applied at different levels of the tree. This can make understanding the combined impact of various features challenging.\n",
    "Fortunately, the feature importance metric provides a way to assess the relative contributions of different features to Decision Tree predictions. Feature importance calculations rely on the model fitting process for Decision Trees. During model fitting, the algorithm evaluates all potential decision rules for every predictor variable at each step of the tree's construction. It selects the decision rule that leads to the most significant improvement in prediction, as measured by the chosen criterion (e.g., Gini impurity or Shannon entropy).3\n",
    "Decision Tree complexity can lead to overfitting, where the model performs well on the training data but poorly on new, unseen data. This happens when the model learns the specific nuances and noise in the training data rather than the general underlying patterns.\n",
    "Machine Learning offers a solution to this issue through regularization. Regularization involves using model complexity tuning parameters to constrain the model fitting process, preventing the model from becoming overly complex.\n",
    "You correctly point out that GridSearchCV is a useful technique for finding the optimal setting for the max_depth regularization tuning parameter. GridSearchCV is a general method for addressing the challenges of model complexity and overfitting in machine learning models.\n",
    "In addition to max_depth, the sources list other regularization tuning parameters that can be used for Decision Trees. These parameters act as either hard constraints on the model fitting process or model complexity penalties. Examples include min_samples_split, min_samples_leaf, and ccp_alpha.\n",
    "By applying regularization techniques like GridSearchCV and adjusting appropriate tuning parameters, you can prevent overfitting in Decision Tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e374c3",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:The last two responses highlight the complexities and challenges associated with Decision Trees and offer solutions from the Machine Learning framework.\n",
    "Decision Trees, despite their apparent simplicity, can become incredibly complex models.1 2\n",
    "Unlike linear models where the linear form and coefficients directly show how predictor variables impact predictions, Decision Trees use a series of decision rules applied at different nodes to arrive at predictions, making interpretation much more challenging.\n",
    "The feature importance metric helps assess the relative contributions of different features in Decision Tree predictions.\n",
    "During model fitting, the Decision Tree algorithm considers all possible decision rules for all features at every stage of the tree construction.\n",
    "The decision rule that leads to the most significant improvement in prediction, measured by criteria like Gini impurity or Shannon entropy, is chosen.\n",
    "By tracking the improvement from each decision rule, the algorithm can calculate the relative contribution of each predictor variable, resulting in the feature importance score.\n",
    "The complexity of Decision Trees makes them susceptible to overfitting, where the model learns the noise in the training data rather than the generalizable patterns.\n",
    "Machine Learning addresses overfitting through regularization, using tuning parameters to control the complexity of the model during model fitting.\n",
    "max_depth is one such regularization tuning parameter, limiting the depth of the Decision Tree.\n",
    "Other tuning parameters include min_samples_split, min_samples_leaf, and ccp_alpha.\n",
    "These act as hard constraints or complexity penalties during the model fitting process.\n",
    "GridSearchCV is a useful technique for finding the optimal setting for tuning parameters, helping to prevent overfitting.\n",
    "By utilizing regularization techniques like GridSearchCV and understanding feature importance, you can build Decision Tree models that make accurate and generalizable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef7566",
   "metadata": {},
   "source": [
    "9.In linear regression, coefficients reflect the magnitude and direction of the linear relationship between a predictor variable and the outcome, enabling direct interpretation of the impact of changes in the predictor on the predicted outcome.1 2  In contrast, feature importances in decision trees represent the overall contribution of a predictor variable to the model's predictive accuracy, considering all the decision rules involving that variable throughout the tree structure.1 2 3  This makes interpreting feature importances less straightforward than coefficients in linear models, as they don't directly indicate the direction or magnitude of the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669579a9",
   "metadata": {},
   "source": [
    "https://notebooklm.google.com/notebook/8a81180c-a3df-4a1e-ad1c-da101a53a103?_gl=1*129t9oq*_ga*MTE3OTQwMTMwNy4xNzI4MDk1Nzc5*_ga_W0LDH41ZCB*MTczMTg3OTU1Ny4zLjAuMTczMTg3OTkwOS4wLjAuMA..\n",
    "SUMMARY:The last response explained the differences in interpreting coefficients in linear model regression versus feature importances in decision trees:\n",
    "In linear regression, the coefficients provide a direct and interpretable measure of the relationship between a predictor variable and the outcome. You can understand how changes in a predictor variable affect the predicted outcome by simply examining the coefficient's magnitude and sign.1 2\n",
    "Feature importances in decision trees don't offer the same level of direct interpretability. They represent the overall contribution of a predictor variable to the model's accuracy, considering all the decision rules involving that variable throughout the tree.1 2  This makes understanding the precise nature and direction of the relationship between the predictor variable and the outcome more difficult than in linear regression.1 2\n",
    "The sources further emphasize the complexity of decision trees compared to the simplicity of linear models in terms of understanding how predictor variables influence predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21ccc6",
   "metadata": {},
   "source": [
    "10.YES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
